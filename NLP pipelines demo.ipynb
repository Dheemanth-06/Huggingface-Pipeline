#1:
from transformers import pipeline

qa_pipeline = pipeline("question-answering")

context = """The Eiffel Tower is one of the most famous landmarks in the world.
It was constructed in 1889 in Paris, France, and stands at a height of 330 meters."""

question = "Where is the Eiffel Tower located?"

result = qa_pipeline(question=question, context=context)
print(result)

OUTPUT:-
No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use cpu
{'score': 0.8780861496925354, 'start': 97, 'end': 110, 'answer': 'Paris, France'}


#2:
summarizer = pipeline("summarization")

text = """Artificial Intelligence (AI) is transforming industries by automating
tasks, improving efficiency, and enabling data-driven decision-making.
Companies across healthcare, finance, and transportation are integrating AI
to enhance productivity and customer experiences."""

summary = summarizer(text, max_length=30, min_length=10, do_sample=False)
print(summary)

OUTPUT:
[{'summary_text': ' Artificial Intelligence (AI) is transforming industries by automating tasks, improving efficiency, and enabling data-driven decision-making . Companies across'}]


#3:
from transformers import pipeline
import pandas as pd

table_qa = pipeline("table-question-answering")

data = {
    "Name": ["Alice", "Bob"],
    "Age": ["25", "30"],
    "City": ["New York", "San Francisco"]
}
table = pd.DataFrame.from_dict(data)

question = "Where does Bob live?"
result = table_qa(table=table, query=question)
print(result)

OUTPUT:
{'answer': 'San Francisco', 'coordinates': [(1, 2)], 'cells': ['San Francisco'], 'aggregator': 'NONE'}


#4:
text2text = pipeline("text2text-generation")
text = "Convert this sentence into a question: The sky is blue."
result = text2text(text)
print(result)

OUTPUT:
[{'generated_text': 'False'}]


#5:
classifier = pipeline("text-classification")
text = "I absolutely love this new AI model!"
result = classifier(text)
print(result)

OUTPUT:
[{'label': 'POSITIVE', 'score': 0.9998767375946045}]


#6:
generator = pipeline("text-generation")
prompt = "The future of AI is"
result = generator(prompt, max_length=30, num_return_sequences=1)
print(result)

OUTPUT:
[{'generated_text': 'The future of AI is in the hands of smart machines."\n\nThat\'s from an interview I did with CTO Marko Manko over'}]


#7:
ner_pipeline = pipeline("token-classification", grouped_entities=True)

text = "Elon Musk founded SpaceX in 2002 and acquired Twitter in 2022."
result = ner_pipeline(text)
print(result)

OUTPUT:
[{'entity_group': 'PER', 'score': 0.99783283, 'word': 'Elon Musk', 'start': 0, 'end': 9}, {'entity_group': 'ORG', 'score': 0.999151, 'word': 'SpaceX', 'start': 18, 'end': 24}, {'entity_group': 'ORG', 'score': 0.99849725, 'word': 'Twitter', 'start': 46, 'end': 53}]


#8:
translator = pipeline("translation_en_to_fr")
text = "Hello, how are you?"
result = translator(text)
print(result)

OUTPUT:
[{'translation_text': 'Bonjour, comment Ãªtes-vous?'}]


#9:
zero_shot = pipeline("zero-shot-classification")
text = "I love playing football during the weekends."
labels = ["sports", "technology", "food"]

result = zero_shot(text, candidate_labels=labels)
print(result['labels'])
print(result['scores'])

OUTPUT:
['sports', 'technology', 'food']
[0.9965085983276367, 0.0019449957180768251, 0.0015463430900126696]
